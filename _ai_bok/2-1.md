---
description: "The structure for organizing and managing AI should accomplish two broad goals: enhancing mission/business effectiveness and ensuring practitioner effectiveness."
slug: organizing-managing-ai
title: Organizing and managing AI 
---

The structure for organizing and managing AI should accomplish two broad goals: enhancing mission/business effectiveness and ensuring practitioner effectiveness. 
{: .intro }

## Supporting mission and business objectives: including AI knowledge in mission and program offices

The level of AI investment should match the level of value it adds in achieving mission or business goals. Therefore, mission or business executives should allocate funding for AI. Think about your mission and  business objectives, and which tasks to support those objectives could be done better with the addition of AI techniques.

Concretely, this means mission areas should use integrated product teams that include AI talent as the basic unit of operations. These teams focused on implementing and running major products or services will need to be more specialized, but they should still ultimately report to and be accountable to whatever mission or business center they support. 

Embedding AI-focused work in the mission centers and with the customer ensures that AI is integrated into how the agency functions and achieves its mission and business goals. AI should not be approached in a silo, but rather integrated into the rest of the workforce and the agency’s core workflows. 


> Don’t do AI just for the sake of doing AI; use AI where it will be an effective tool for dealing with the current and future state of the world.
> 
> Embed AI work within the organization’s core mission centers rather than a separate overarching group. The AI workforce will then be spread across the organization, not siloed into one specific area.
> 
> Invest in AI tools, talent, and tradecraft within the business centers that are most able to use it. The mission owners who are best able to judge AI’s value to their objectives make those decisions.
> 
> Advanced technical infrastructure, security, legal, and acquisition support should come from a central AI resource. 
> 
> Supporting the AI practitioner’s effectiveness: creating a technical AI resource to support mission and program offices 
{: .ai-bok-feature }


## Supporting the AI practitioner’s effectiveness:  creating a technical AI resource to support mission and program offices 

To ensure mission and business alignment, the AI workforce should be spread throughout the agency. But how do we ensure that individual AI practitioners have the infrastructure they need to succeed wherever they physically sit? 
{: .intro }

- Addressing this requires an organizational resource that functions as the one-stop-shop to provide all of the practitioner's technical resource needs: 
    - Technical tools 
    - development environments, 
    - spinning up servers, 
    - accessing code libraries, etc.

  **Technical resources means tools and software, not developer services.** AI practitioners across the organization can easily access centralized tools that they need to build and implement an AI system.

- Institutional resources 
    - security review, 
    - legal review, 
    - acquisition support for buying licenses, etc. 

  AI practitioners will also need support and guidance in areas such as legal considerations, acquisition, and security to fully integrate an AI system into their existing processes. The centralized AI resource will serve as a hub of AI expertise for program offices to seek the support they need. These are members  who help make up the Integrated Agency Team (IAT).

- Job/career considerations
    - Recruitment
    - Certification
    - Training
    - Career path

  The AI resource should also take on AI talent recruitment, certification, training, and career path for AI jobs and roles. Mission and business centers using AI practitioners can then expect that AI talent will be of consistent quality and able to enhance mission and business effectiveness regardless of the customer's own technical understanding of AI. 

Chief information offices, chief Information security offices, chief data offices, acquisition and procurement offices, and privacy and legal offices must collaborate to establish this AI resource to support AI professionals in the mission and program offices.

> Embed AI professionals in the mission centers and program offices, but they should have access to a one-stop-shop for AI tools and resources in a central AI resource.
> 
> The centralized AI resource provides technical and infrastructure support as well as access to legal, security, and acquisition support for AI professionals in the mission center and program office to succeed in AI adoption efforts. 
{: .ai-bok-feature }

![Organizing and managing AI](../images/organizing-managing-ai.png)


## Path to the goal: getting to a central AI resource 

Understandably, agencies may be in the early stages of their AI integrated product team (IPT) journey; fortunately, the path to get there is a natural and methodical one. 
{: .intro }

Mission leaders and AI practitioners should identify use cases where AI could easily have a large impact. Once found, they can make the case to the executives in charge of the mission or business area that covers those use cases and start building AI capabilities in those mission/business centers. 

Most likely, these early teams will need to supply their own ad hoc infrastructure, which will limit their effectiveness. Make the use case so compelling—ideally to agency leadership—that the teams are still able to show great value to the mission/business center. Early wins build momentum toward more mission centers and program offices wanting to incorporate AI capability to boost their own effectiveness. 

After more than a few mission centers and program offices start building AI, you should have critical mass. Move the AI infrastructure provider to a more accessible part of the organization, towards the central AI resource.

Crucially, these steps do not require immediate enterprise-wide changes. This model works at whatever scale of organic AI adoption the agency can handle at the time. Adding AI personnel to more mission centers and program offices and continuing to scale up AI practitioners’ skills offers a natural and gradual path to the goal state of enabling all agency functions to use AI. 

![Organizing and managing AI](../images/organizing-managing-ai-part-2.png)


> Start small with a use case that focuses on a unique mission or program challenge.
> 
> As more small use cases emerge, consolidate technical infrastructure to support these AI projects to avoid buying duplicate and overlapping infrastructure. Infrastructure may sit in one specific mission center or program office, but share it  with others.
> 
> Once there is a critical mass, which will depend on your agency, move towards a central AI technical resource at the enterprise level
{: .ai-bok-feature }


## Center AI support around the use case, not technical skills

Perhaps the most common pitfall to avoid is creating a central group of practitioners that does AI work for different mission areas or program offices upon request. One example of this is a central team of data scientists that can be loaned to a specific mission center or program office. 
{: .intro }

Although this is tempting in the early stages when infrastructure, personnel, and funding are limited, this strategy creates an organizational structure that is extremely difficult to grow out of even when it is clearly no longer effective. 

Many agencies fell into this trap when setting up their IT workforce. Having the IT workforce siloed off as a special branch prevents them from integrating into the rest of the agency workforce. They remain a special service, rather than a standard part of how the agency operates. 

Even when leaders recognize that IT work should and can be done with personnel native to the various mission centers and program offices, the IT office will naturally discourage such encroachments on their turf. In the meantime, the IT office cannot handle the increasingly domain-specific requirements of so many mission and business centers. 

AI needs to avoid IT’s fate by always being directly accountable to the customers that the work is supposed to support; **AI practitioners ultimately report to mission center and program office leaders**, just as all other personnel who work on those missions and business functions do. AI talent must be placed in the organizational chart, not in a central AI group or shared service. 

> Avoid centralizing AI practitioners and leaders in one unit. AI talent must be accountable to the business needs and therefore should exist across the organization.
> 
> Avoid “data scientist” or “AI staff” for loan situations that remove accountability to the mission center or program office responsible for implementing the AI solution.
{: .ai-bok-feature }


## Doing project based AI: The Integrated Product Team

Certainly, organizing an agency for successful AI development can be a challenge. With the organizational structure we’ve already shared in mind, let’s shift our focus to the actual personnel and staffing required to implement an AI project.
{: .intro }

The centralized AI resource that provides tooling and security, legal, and acquisition support,  combined with mission-based AI practitioners, make up the Integrated Product Team (IPT). The IPT is responsible for implementing AI products, systems and solutions.

As their output and work products are generally software, structure these teams similar to a modern software team, applying agile/scrum principles. Led by a technical program manager, the bulk of the team should consist of AI practitioners and software engineers. 

But in the spirit of the IPT, also consider roles like change management experts who can help develop any training or changes to processes or workflows that may be necessary, and user researchers who can generate real-time feedback about the work being done.
 
What makes an IPT team made up of a variety of roles so successful is that they each have the perspectives and knowledge necessary to ensure true value is delivered at all points of a project. The IPT will make many of the decisions that will impact the final deliverable(s). 

![Organizing and managing AI](../images/organizing-managing-ai-part-3.png)

## Security, legal, and acquisition support for practitioners: the Integrated Agency Team

Practitioners embedded within mission teams can leverage more standard tools, policies, and guidance for their AI work. Therefore, they may not need as much security, legal, and acquisition support on a day-to-day basis. 
{: .intro }

On the other hand, IPTs usually deal with more novel situations that require deeper support from security, legal, and acquisition personnel. While an IPT should be structured like a typical modern software development team, consider augmenting the Integrated Agency Team (IAT) that supports the IPT with security, legal, and acquisition professionals needed to successfully launch the project.
 
The IAT should address these types of issues: 
- data rights, 
- intellectual property provisions, 
- end-user licensing agreements, 
- appropriations implications for different types of pricing,
- the extent that software or hardware must be integrated into the existing infrastructure, and
- security measures that must be complied with to start a pilot or scale a solution. 

The individuals who answer these questions tend to be found in the Office of General Counsel (OGC), or wherever the Chief Financial Officer (CFO),Chief Information Officer (CIO), Chief Technology Officer (CTO), or Chief Information Security Officer (CISO) are housed. 

As with all other support services, you should coordinate these through the central AI resource so they will be easier to access. Some agencies’ offices may lack enough specific knowledge to guide AI use. You’ll need to provide training to build this knowledge.
 
Meeting with these individuals that make up the IAT at the beginning of your program’s efforts will help establish the operating framework within the team as well as pain points that must be solved before moving into more involved phases of the project. Meeting with the IAT in the middle of planning will help validate the ideas being explored and ensure they are practical. Finally, meeting with everyone right before starting a solicitation or internal development effort in earnest will ensure that the entire organization is not only on the same page, but ready to react should a critical issue arise that has to be escalated. 

Given AI’s emerging and rapidly evolving nature, new and unforeseen challenges may come up at any time. Build a process that allows IPTs to ask questions or clarify issues at any point in the process, like, for example, a legal concern.
 
AI implementation is not only important from a technical perspective, but also from an administrative perspective. AI’s technological implications will affect many people, from the citizens interacting with the agency or department to the employees supporting the program itself.

The value of an IAT is to support the IPT members who will actually develop and manage the day-to-day affairs, and finally, the true end-user who will actually interact with the final product. Without their insight, the IAT’s input would go into vacuum, and the ability to achieve the true practical solution that results from a cross-functional collaboration is lost.


> Offices of General Counsel (OGC), Chief Financial Officer (CFO), Chief Information Officer (CIO), Chief Technology Officer (CTO), or Chief Information Security Officer (CISO) may need to provide answers or support to the Integrated Product Team (IPT). However, some offices may not be ready to support  AI. Your agency may first require AI training. 
> 
> AI projects have many unseen or unique challenges and IPTs need easy access to support (technical, legal, etc.) these services as they develop.
{: .ai-bok-feature }









